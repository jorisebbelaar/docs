---
title: "Agent Node"
description: "Discover how to integrate Large Language Models into your workflows using the AgentNode class powered by PydanticAI."
---

# Agent Node

## Overview

<Info>
The `AgentNode` class is a specialized type of node designed for tasks that require the use of large language models (LLMs). It serves as an integration layer around **PydanticAI**, enabling streamlined configuration and execution of LLM-powered workflows.
</Info>

To implement a custom `AgentNode`, you must define two main methods:

<CardGroup cols={2}>
  <Card title="get_agent_config()" icon="cog">
    Returns an `AgentConfig` instance that specifies how the underlying agent should behave, including its prompt, expected output, model provider, and model name.
  </Card>
  <Card title="process()" icon="play">
    Contains the logic to process a given task using the LLM, leveraging the configuration provided.
  </Card>
</CardGroup>

The class also includes helper definitions for dependencies (`DepsType`) and expected outputs (`OutputType`), which can be customized using Pydantic models.

## AgentNode Class Structure

<Tabs>
  <Tab title="AgentConfig">
    ```python
    @dataclass
    class AgentConfig:
        model_provider: ModelProvider
        model_name: Union[
            OpenAIModelName, AnthropicModelName, GeminiModelName, BedrockModelName
        ]
        output_type: Any = str
        instructions: Optional[str] = None
        system_prompt: str | Sequence[str] = ()
        deps_type: Optional[Type[Any]] = None
        name: str | None = None
        model_settings: ModelSettings | None = None
        retries: int = 1
        output_retries: int | None = None
        tools: Sequence[Tool[AgentDepsT] | ToolFuncEither[AgentDepsT, ...]] = ()
        mcp_servers: Sequence[MCPServer] = ()
        instrument: InstrumentationSettings | bool | None = None
    ```
  </Tab>
  
  <Tab title="AgentNode Base">
    ```python
    class AgentNode(Node, ABC):
        class DepsType(BaseModel):
            pass

        class OutputType(BaseModel):
            pass

        def __init__(self):
            self.__async_client = AsyncClient()
            agent_wrapper = self.get_agent_config()
            self.agent = Agent(
                model=self.__get_model_instance(
                    agent_wrapper.model_provider, agent_wrapper.model_name
                ),
                output_type=agent_wrapper.output_type,
                instructions=agent_wrapper.instructions,
                system_prompt=agent_wrapper.system_prompt,
                deps_type=agent_wrapper.deps_type,
                name=agent_wrapper.name,
                model_settings=agent_wrapper.model_settings,
                retries=agent_wrapper.retries,
                output_retries=agent_wrapper.output_retries,
                tools=agent_wrapper.tools,
                mcp_servers=agent_wrapper.mcp_servers,
                instrument=agent_wrapper.instrument,
            )

        @abstractmethod
        def get_agent_config(self) -> AgentConfig:
            pass

        @abstractmethod
        async def process(self, task_context: TaskContext) -> TaskContext:
            pass
    ```
  </Tab>
</Tabs>

## Using PydanticAI Agent

<Warning>
Since Launchpad v3.0.0, `AgentNode` operates in an asynchronous context. Use the `run()` method on the `Agent` to execute completions. The synchronous `run_sync()` method is no longer suitable here.
</Warning>

### Running a Completion

```python
# ✅ Correct - Use async run method
result = await self.agent.run(user_prompt="Your prompt here")

# ❌ Incorrect - Don't use sync method in async context
result = self.agent.run_sync(user_prompt="Your prompt here")
```

<Tip>
For more details on the `Agent`, please refer to the [PydanticAI Agent documentation](https://ai.pydantic.dev/agents).
</Tip>

## Implementation Examples

### Example 1: Without Dependencies

This example shows a spam filtering agent from the `quickstart` branch:

```python
class FilterSpamNode(AgentNode):
    class OutputType(AgentNode.OutputType):
        reasoning: str = Field(
            description="Explain your reasoning for determining whether the message is written by a human or is spam generated by a bot."
        )
        confidence: float = Field(
            ge=0,
            le=1,
            description="Confidence score for the human vs spam classification.",
        )
        is_human: bool = Field(
            description="Set to True if the message appears to be written by a genuine human; False if it's most likely spam from a bot."
        )

    def get_agent_config(self) -> AgentConfig:
        return AgentConfig(
            system_prompt="You are a helpful assistant that filters messages to determine whether they are written by a human or are spam generated by a bot.",
            output_type=self.OutputType,
            deps_type=None,
            model_provider=ModelProvider.OPENAI,
            model_name="gpt-4o",
        )

    async def process(self, task_context: TaskContext) -> TaskContext:
        event: CustomerCareEventSchema = task_context.event
        result = await self.agent.run(
            user_prompt=event.model_dump_json(),
        )
        task_context.update_node(node_name=self.node_name, result=result)
        return task_context
```

### Example 2: With Dependencies

This example shows a RAG-powered generation node from the `pgvector-rag` branch:

```python
class GenerationNode(AgentNode):
    class DepsType(AgentNode.DepsType):
        context: RetrievalResults

    class OutputType(AgentNode.OutputType):
        answer: str = Field(description="The answer to the query")
        sources: list[str] = Field(description="The sources used to answer the query")
        confidence: float = Field(
            description="The confidence in the answer", ge=0, le=1
        )

    def get_agent_config(self) -> AgentConfig:
        return AgentConfig(
            system_prompt="You are a helpful assistant that can answer questions and provide information based on the retrieved documents.",
            output_type=GenerationNode.OutputType,
            deps_type=GenerationNode.DepsType,
            model_provider=ModelProvider.OPENAI,
            model_name="gpt-4.1",
        )

    async def process(self, task_context: TaskContext) -> TaskContext:
        deps = GenerationNode.DepsType(
            context=task_context.nodes["RetrievalNode"]["results"],
        )

        # Register the dynamic system prompt function
        @self.agent.system_prompt
        def add_rag_context(ctx: RunContext[GenerationNode.DepsType]) -> str:
            return f"Here are the documents I found for your query:\n{ctx.deps.context.model_dump_json(indent=2)}"

        result = await self.agent.run(
            user_prompt=task_context.event.query,
            deps=deps,
        )

        task_context.update_node(node_name=self.node_name, result=result)

        return task_context
```

## Key Features

<AccordionGroup>
  <Accordion title="Type-Safe Outputs">
    Define structured outputs using Pydantic models for consistent, validated results that can be easily processed by subsequent nodes.
  </Accordion>
  
  <Accordion title="Flexible Dependencies">
    Use the `DepsType` to inject contextual information from previous nodes, enabling complex RAG patterns and multi-step reasoning.
  </Accordion>
  
  <Accordion title="Multiple Model Providers">
    Support for OpenAI, Anthropic, Google Gemini, and AWS Bedrock models, allowing you to choose the best model for your specific use case.
  </Accordion>
  
  <Accordion title="Dynamic System Prompts">
    Register dynamic system prompt functions that can access dependencies and modify the agent's behavior based on context.
  </Accordion>
  
  <Accordion title="Built-in Retry Logic">
    Configurable retry mechanisms for both general failures and output validation failures, ensuring robust LLM interactions.
  </Accordion>
  
  <Accordion title="Tool Integration">
    Support for tools and MCP servers, enabling agents to perform actions beyond text generation.
  </Accordion>
</AccordionGroup>

## Best Practices

<Steps>
  <Step title="Design Clear Output Types">
    Define specific, well-documented Pydantic models for your expected outputs. This ensures consistency and makes debugging easier.
  </Step>
  
  <Step title="Use Dependencies Wisely">
    Leverage the `DepsType` to pass relevant context from previous nodes, but avoid passing unnecessary data that might confuse the model.
  </Step>
  
  <Step title="Craft Effective System Prompts">
    Write clear, specific system prompts that guide the model toward your desired behavior. Use dynamic prompts when context is important.
  </Step>
  
  <Step title="Handle Errors Gracefully">
    Configure appropriate retry settings and implement error handling in your process method to deal with model failures.
  </Step>
</Steps>

<Info>
The AgentNode provides a powerful way to integrate AI capabilities into your workflows while maintaining the same consistent interface as other node types.
</Info>